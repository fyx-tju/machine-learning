{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fuyuxin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_data = pd.read_csv(\"../data/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"../data/titanic/test.csv\")\n",
    "\n",
    "features = train_data.columns.values.tolist()\n",
    "features.remove(\"Survived\")\n",
    "train_x = train_data[features]\n",
    "train_y = train_data[\"Survived\"]\n",
    "\n",
    "full_x = [train_x, test_data]\n",
    "from sklearn import preprocessing\n",
    "def transform_feature(x,feature):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le = le.fit(x[feature])\n",
    "    x[feature] = le.fit_transform(x[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "   Sex   Age     Fare  Cabin  Embarked  FamilySize  IsAlone  \n",
       "0    1  22.0   7.2500     47         2           2        1  \n",
       "1    0  38.0  71.2833     81         0           2        1  \n",
       "2    0  26.0   7.9250     47         2           1        1  \n",
       "3    0  35.0  53.1000     55         2           2        1  \n",
       "4    1  35.0   8.0500     47         2           1        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "for data in full_x:\n",
    "    age_filled = data.Age.dropna().median()\n",
    "    data.Age = data.Age.fillna(age_filled)\n",
    "    cabin_filled = data.Cabin.value_counts().index[0]\n",
    "    data.Cabin = data.Cabin.fillna(cabin_filled)\n",
    "    fare_filled = data.Fare.dropna().median()\n",
    "    data.Fare = data.Fare.fillna(fare_filled)\n",
    "    embarked_filled = data.Embarked.value_counts().index[0]\n",
    "    data.Embarked = data.Embarked.fillna(embarked_filled)\n",
    "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "    data['IsAlone'] = 0\n",
    "    data['IsAlone'][data['FamilySize'] != 0] = 1\n",
    "    transform_feature(data,'Sex')\n",
    "    transform_feature(data,'Cabin')\n",
    "    transform_feature(data,'Embarked')\n",
    "    transform_feature(data,'Ticket')\n",
    "    data.drop(['SibSp','Parch','Ticket'],axis = 1,inplace=True)\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.Age[train_x.Age <= 10] = 0\n",
    "train_x.Age[(train_x.Age > 10) & (train_x.Age <= 20)] = 1\n",
    "train_x.Age[(train_x.Age <= 30) & (train_x.Age > 20)] = 2\n",
    "train_x.Age[(train_x.Age <= 40) & (train_x.Age > 30)] = 3\n",
    "train_x.Age[(train_x.Age <= 50) & (train_x.Age > 40)] = 4\n",
    "train_x.Age[(train_x.Age <= 60) & (train_x.Age > 50)] = 5\n",
    "train_x.Age[(train_x.Age <= 70) & (train_x.Age > 60)] = 6\n",
    "train_x.Age[train_x.Age > 70] = 7\n",
    "test_data.Age[test_data.Age <= 10] = 0\n",
    "test_data.Age[(test_data.Age > 10) & (test_data.Age <= 20)] = 1\n",
    "test_data.Age[(test_data.Age <= 30) & (test_data.Age > 20)] = 2\n",
    "test_data.Age[(test_data.Age <= 40) & (test_data.Age > 30)] = 3\n",
    "test_data.Age[(test_data.Age <= 50) & (test_data.Age > 40)] = 4\n",
    "test_data.Age[(test_data.Age <= 60) & (test_data.Age > 50)] = 5\n",
    "test_data.Age[(test_data.Age <= 70) & (test_data.Age > 60)] = 6\n",
    "test_data.Age[test_data.Age > 70] = 7\n",
    "\n",
    "bins = (-1, 0, 8, 15, 31, 1000)\n",
    "group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n",
    "categories = pd.cut(train_x.Fare, bins, labels=group_names)\n",
    "\n",
    "train_x.Fare = categories\n",
    "transform_feature(train_x,'Fare')\n",
    "\n",
    "test_data.Fare = categories\n",
    "test_data.Fare.value_counts()\n",
    "transform_feature(test_data,'Fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = [train_x, test_data]\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.concat([train_x,pd.get_dummies(train_x.Pclass,prefix=\"Pclass\")],axis=1)\n",
    "test_data = pd.concat([test_data,pd.get_dummies(test_data.Pclass,prefix=\"Pclass\")],axis=1)\n",
    "train_x = pd.concat([train_x,pd.get_dummies(train_x.Embarked,prefix=\"Embarked\")],axis=1)\n",
    "test_data = pd.concat([test_data,pd.get_dummies(test_data.Embarked,prefix=\"Embarked\")],axis=1)\n",
    "train_x.drop(['Pclass','Embarked','Name','Title'],axis=1,inplace=True)\n",
    "test_data.drop(['Pclass','Embarked','Name','Title'],axis=1,inplace=True)\n",
    "\n",
    "train_x,val_x,train_y,val_y = train_test_split(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mynn(object):\n",
    "    def creat_model(self):\n",
    "        for i in range(self.n_layers_):\n",
    "            self.weights.append(tf.Variable(tf.truncated_normal([self.n_weights_[i],self.n_weights_[i+1]],mean=0,stddev=5)))\n",
    "            self.bias.append(tf.Variable(tf.constant(0.1,shape=[self.n_weights_[i+1]])))\n",
    "            if i == 0 :\n",
    "                self.xs.append(tf.nn.relu(tf.matmul(self.X,self.weights[i]) + self.bias[i]))\n",
    "            else:\n",
    "                self.xs.append(tf.nn.relu(tf.matmul(self.xs[i-1],self.weights[i]) + self.bias[i]))\n",
    "        self.weights.append(tf.Variable(tf.truncated_normal([self.n_weights_[self.n_layers_],2],mean=0,stddev=0.1)))\n",
    "        self.bias.append(tf.Variable(tf.constant(0.1,shape=[2,])))\n",
    "        if self.n_layers_ == 0:\n",
    "            self.pre_y = tf.matmul(self.X,self.weights[self.n_layers_]) + self.bias[self.n_layers_]\n",
    "        else:\n",
    "            self.pre_y = tf.matmul(self.xs[self.n_layers_-1],self.weights[self.n_layers_]) + self.bias[self.n_layers_]\n",
    "        self.pre_y_o = tf.nn.softmax(self.pre_y)\n",
    "    def __init__(self,n_layers,n_weights):\n",
    "        self.n_layers_ = n_layers\n",
    "        self.n_weights_ = [13]\n",
    "        self.weights = list()\n",
    "        self.bias = list()\n",
    "        self.xs = list()\n",
    "        self.n_weights_ += n_weights    \n",
    "        self.X = tf.placeholder(tf.float32, shape=(None, 13))\n",
    "        self.Y = tf.placeholder(tf.float32, shape=(None,2))\n",
    "        self.creat_model()\n",
    "        self.loss()\n",
    "        self.global_iter = tf.Variable(0, name='global_iter', trainable=False)\n",
    "        self.lr = tf.train.polynomial_decay(0.0001, self.global_iter, 2000, end_learning_rate=0.0, power=0.9)\n",
    "        self.optimizer = tf.train.MomentumOptimizer(self.lr, 0.9)\n",
    "        self.train_op = tf.train.AdamOptimizer(0.001).minimize(self.total_loss)\n",
    "        #self.train_op = self.optimizer.minimize(self.total_loss, global_step=self.global_iter)\n",
    "    def loss(self):\n",
    "        self.total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.Y,logits=self.pre_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t = train_y.map(lambda x: 0 if x == 1 else 1)\n",
    "train_y = pd.DataFrame({'a':train_t, 'b':train_y})\n",
    "#train_y = train_y.reshape([891,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_m = val_y.map(lambda x: 0 if x == 1 else 1)\n",
    "val_y = pd.DataFrame({'a':train_m, 'b':val_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.21516\n",
      "0.7613882\n",
      "0.6748856\n",
      "0.61970806\n",
      "0.58511794\n",
      "0.5631131\n",
      "0.5468146\n",
      "0.53368294\n",
      "0.5229117\n",
      "0.5141243\n",
      "0.50706196\n",
      "0.50144845\n",
      "0.49698165\n",
      "0.49363485\n",
      "0.49093956\n",
      "0.48895246\n",
      "0.48737478\n",
      "0.4861859\n",
      "0.4852468\n",
      "0.48449585\n",
      "0.4839121\n",
      "0.48347446\n",
      "0.4831488\n",
      "0.4828233\n",
      "0.48260868\n",
      "0.4823298\n",
      "0.48224083\n",
      "0.48204514\n",
      "0.48195767\n",
      "0.48184487\n",
      "0.48176864\n",
      "0.48162198\n",
      "0.48143604\n",
      "0.48137796\n",
      "0.48126754\n",
      "0.48114324\n",
      "0.48110887\n",
      "0.48099884\n",
      "0.48091257\n",
      "0.4808579\n",
      "0.48081544\n",
      "0.48076606\n",
      "0.48077017\n",
      "0.48058903\n",
      "0.4806311\n",
      "0.48051727\n",
      "0.48036742\n",
      "0.4802542\n",
      "0.4802273\n",
      "0.48026714\n"
     ]
    }
   ],
   "source": [
    "model = mynn(1,[6])\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(50000):\n",
    "    #for j in range(len(train_x)):\n",
    "    #    a,b = sess.run([model.train_op,model.total_loss],feed_dict={model.X: train_x.values[j].reshape([-1,13]),model.Y:train_y.values[j].reshape([-1,2])})\n",
    "    a,b=sess.run([model.train_op,model.total_loss],feed_dict={model.X: train_x,model.Y:train_y.values.reshape([-1,2])})\n",
    "    if i%1000==0:\n",
    "        print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_y1 = sess.run(model.pre_y_o,feed_dict={model.X: train_x})\n",
    "pre_1 = pre_y1.argmax(axis=1)\n",
    "pre_y2 = sess.run(model.pre_y_o,feed_dict={model.X: val_x})\n",
    "pre_2 = pre_y2.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8143712574850299, 0.7847533632286996)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=(pre_1==train_y.values.transpose([1,0])[1])\n",
    "b=(pre_2==val_y.values.transpose([1,0])[1])\n",
    "np.count_nonzero(a)/668,np.count_nonzero(b)/223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418,)\n"
     ]
    }
   ],
   "source": [
    "pre_y = sess.run(model.pre_y_o,feed_dict={model.X: test_data})\n",
    "pre_0 = pre_y.argmax(axis=1)\n",
    "print(pre_0.shape)\n",
    "result = pd.DataFrame({'PassengerId':test_data.PassengerId,'Survived':pre_0})\n",
    "result.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
